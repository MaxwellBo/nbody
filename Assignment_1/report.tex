\documentclass[11pt,a4paper]{article}

\usepackage{fullpage}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\usepackage{graphicx}
\graphicspath{ {images/} }

\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}

\begin{document}

\title{COSC3500 \\ 2D Orbital Simulation Report}
\author{Maxwell Bo (43926871)}
\date{August 17, 2018}
\maketitle

% Description of problem - readable and covers all salient points - /2
\subsection*{Description}
The task was to create a stock-standard, 2-dimensional gravitational $n$-body simulator. 
All bodies were to be assumed to be point masses. The simulation was to be accurate, maintaining a constant total energy, and exhibiting phenomena such as apsidal precession. 
The simulation was to accept arguments specifying the granularity of the simulation (number of time steps, number of instances of data export), and a file specifiying masses and their initial positions and velocities. 
The simulation was to produce its output as fast as possible, with minimal slowdown with an increasing $n$ number of bodies. 

The simulator did not need to handle collisions between bodies.
The MS1 simulator was to be free of OpenMP multiprocessing, which would be implemented in preparation for the MS2 submission.

% Description of implementation - is coherent and has sufficient depth and detail - /5
\subsection*{Implementation}

At a high-level, the initial naive simulator:

\begin{enumerate}
    \item Parsed input parameters and files
    \item Constructed \texttt{Body} class instances, representing each point mass
    \item Packed the \texttt{Body}s into a \texttt{std::vector<Body>}, to maximize cache locality
    \item Calculated forces between all pairwise combinations of $n$-bodies ($O(n^2)$)
    \item Performed Euler's method to derive new velocities and positions
    \item Output all necessary data
    \item \texttt{GOTO 4}
\end{enumerate}

By using a Quadtree, (`a tree datastructure in which each internal node has exactly four children') and the \textit{Barnes-Hut} algorithm\cite{barnes86a}, the total cost of force calculation could be reduced to $O(n \log n)$, by grouping close-together bodies and approximating forces between the singular grouped pseudo-body, and distant bodies. New Quadtrees were constructed on each seperate simulation step.

Dehen and Read note that the Euler method `performs very poorly in practice', further noting that `errors are proportional to $\Delta t^2$'. They contrast it with the second-order \textit{Leapfrog} symplectic integrator, which is `heavily used in collisionless N-body applications'.\cite{dehen11a}

\textit{Leapfrog} can be expressed many in forms\cite{Skeel1993} including a synchronised form:

\begin{align*}
x_{i}&=x_{i-1}+v_{i-1/2}\,\Delta t\\
a_{i}&=F(x_{i})\\
v_{i+1/2}&=v_{i-1/2}+a_{i}\,\Delta t\\
\end{align*}

which only requires a single acceleration calculation per every two half timesteps (the timestep $\Delta t$ must be constant to maintain stability), and a `kick-drift-kick' form

\begin{align*}
v_{i+1/2}&=v_{i}+a_{i}{\frac {\Delta t}{2}}\\
x_{i+1}&=x_{i}+v_{i+1/2}\Delta t\\
v_{i+1}&=v_{i+1/2}+a_{i+1}{\frac {\Delta t}{2}}
\end{align*}

that is stable with variable timstepping, but incurs an additional acceleration calculation per every two half timesteps.

The synchronised form was implemented, but attempts to implement the kick-drift-kick form, and variable timestepping, were left unfinished.

Thus, the final implementation:

\begin{enumerate}
    \item Parsed input parameters and files
    \item Constructed \texttt{Body} class instances, representing each point mass
    \item Packed the \texttt{Body}s into a \texttt{std::vector<Body>}, to maximize cache locality
    \item Inserted all \texttt{Body}s into a fresh \texttt{QuadTree} on full timesteps, traversing the \texttt{QuadTree} with every \texttt{Body} to calculate forces ($O(n \log n)$)
    \item Performed the appropriate \textit{Leapfrog} step to derive new velocities \textit{or} positions
    \item Output all necessary data
    \item \texttt{GOTO 4}
\end{enumerate}

% Why do you believe it is correct - /3
\subsection*{Correctness}

I personally believe that the simulation is relatively accurate. By visualising the results with \texttt{matplotlib}, we see something that resembles an $n$-body simulator. The total energy is flat, observing coefficients of variation as low as 0.001\%. Euler's method consistently demonstrated coefficients of variation three times higher than that of \textit{Leapfrog}. Due to recommendations by literature, and observed data, the use of Euler's method was gradually phased out during my testing to speed up the process.

\textit{Barnes-Hut} caused a significant increase in observed coefficient of variation, averaging 0.08\% across multiple runs. Furthermore, total energy was observed to step up and down at varying intervals\ref{fig:anomaly}. I suspect that this was because certain force calculations were causing groups of bodies to be approximated as a single pseudobody, after other had strayed too far from the pseudobody's quadtree's node's centre of mass.

When bodies are in close proxmity, anomalous total energies are observed\ref{fig:anomaly}. Furthermore, simulations with higher numbers of bodies produce more random low energy outliers (likely due to a greater number of close encounters). There seems to be no signficant difference between Euler method and \textit{Leapfrog}, with respect to observation of anomalies.


\begin{figure}[b]
\caption{Observed energy anomaly while bodies in close proxmity - Leapfrog}
\centering
\label{fig:anomaly}
\includegraphics[width=\textwidth]{energy_anomaly}
\end{figure} 

\begin{figure}[b]
\caption{Barnes-Hut energy variation - Leapfrog}
\centering
\label{fig:barnes_hut}
\includegraphics[width=\textwidth]{barnes_hut}
\end{figure} 

% Scaling or other performance discussion - /2
\subsection*{Performance \& Scaling}

Henceforth, the use of the `recognizable' refers to eyeballing the output data, and making no significant effort to investigate the data more rigorously.

The \textit{Barnes-Hut} algorithm appeared to be dominated by its constant factor.\ref{fig:performance} Generating input files with a high number of bodies that did not cause 'spontaneous combustion' (where bodies would fly away from each other in every direction), and unconstrained Quadtree growth (where bodies achieve escape velocity, rapidly expanding the size of the tree and causing a collapse in simulation accuracy) proved difficult. Further testing on \texttt{goliath} is needed to discover the $n$ that causes \textit{Barnes-Hut} to be more performant than the brute-force approach.

Strangely, $n = 16$ with \textit{Barnes-Hut} enabled took longer than expected, when compared to $n \in \{ 4, 8, 12 \}$. Further investigation is required.
\begin{figure}[b]
\caption{Scaling characteristics}
\centering
\label{fig:performance}
\includegraphics[width=\textwidth]{performance}
\end{figure} 

The addition of the 
\texttt{-march=native} compiler flag, which enables the use of all CPU specific instructions, provided no recognizable improvement in running time, but was left enabled in the instance that it improved performance on \texttt{goliath}.

The use of both th GCC and Clang Profile-Guided Optimisation features provided no recognizable improvement in running time.

Distressingly, \texttt{-O0}, \texttt{-O1}, \texttt{-O2}, \texttt{-O3} showed no recognizable improvement in running time. \texttt{-Ofast} led to an -4\%-ish performance regression.

By profiling with \texttt{callgrind}, we saw that execution was dominated by only one incredibly costly user-defined method, with an exclusive cost of 26.33\% of total running time.

\includegraphics[width=\textwidth]{profile}

Performance fixes were divised.

\begin{verbatim}
 void Body::exert_force_unidirectionally(const Body& there) {
     const double m1 = m;
     const double m2 = there.m;

     const double delta_x = there.x - x;
     const double delta_y = there.y - y;
     
-    const double r = distance(x, y, there.x, there.y);
+    const double r = hypot(delta_x, delta_y);
-    const double r2 = r * r;
+    const double r2 = pow(r, 2);

     const double F = (G * m1 * m2) / r2;

     // turn the displacement vector between our two points into a force vector
     // of the desired magnitude
     const double scale_factor = F / r;

     Fx += delta_x * scale_factor;
     Fy += dumpsdelta_y * scale_factor;
 }
\end{verbatim}

Instead of recalculating $\Delta x$ and $\Delta y$ twice (the second time in \texttt{distance}), we calculate them only once and make a direct call to \texttt{hypot}, rather than making a call to \texttt{distance}. We also used the specialized \texttt{pow} provided by \texttt{cmath}. This yielded a recognizable 15\%ish performance improvement. 

\begin{verbatim}
diff --git a/Assignment_1/src/Body.cpp b/Assignment_1/src/Body.cpp

+void Body::exert_force_bidirectionally(Body& there) {
+    const double m1 = m;
+    const double m2 = there.m;
+
+    const double delta_x = there.x - x;
+    const double delta_y = there.y - y;
+
+    const double r = hypot(delta_x, delta_y);
+    const double r2 = pow(r, 2);
+
+    const double F = (G * m1 * m2) / r2;
+
+    // turn the displacement vector between our two points into a force vector
+    // of the desired magnitude
+    const double scale_factor = F / r;
+
+    Fx += delta_x * scale_factor;
+    Fy += delta_y * scale_factor;
+
+    there.Fx -= delta_x * scale_factor;
+    there.Fy -= delta_y * scale_factor;
+}

diff --git a/Assignment_1/src/main.cpp b/Assignment_1/src/main.cpp
@@ -258,8 +259,7 @@ int main(int argc, char **argv) {
                 for (size_t j = i + 1; j < bodies.size(); j++) {
                     auto& y = bodies[j];
-                    x.exert_force_unidirectionally(y);
-                    y.exert_force_unidirectionally(x);
+                    x.exert_force_bidirectionally(y);
                 }
             }
         }
\end{verbatim}

This fix halved execution time, for obvious reasons.\footnote{I had to throw out all my old profile data}.

\begin{verbatim}
diff --git a/Assignment_1/src/Body.cpp b/Assignment_1/src/Body.cpp
@@ -83,11 +82,11 @@ double Body::kinetic_energy() const {
 double Body::gravitational_potential_energy(const Body& there) const {
     const double R = distance(x, y, there.x, there.y); // final distance, aka, to edge

-    return (-G * m * there.m) / R;
+    return (-Gm * there.m) / R;
 }

@@ -101,7 +100,7 @@ void Body::exert_force_unidirectionally(const Body& there) {

-    const double F = (G * m1 * m2) / r2;
+    const double F = (Gm * m2) / r2;

@@ -113,7 +112,6 @@ void Body::exert_force_unidirectionally(const Body& there) {

-    const double F = (G * m1 * m2) / r2;
+    const double F = (Gm * m2) / r2;

@@ -189,6 +189,7 @@ std::vector<Body> parse_input_file(std::ifstream& input_fh) {

     for (size_t i = 0; i < bodies.size(); i++) {
         bodies[i].m = masses[i];
+        bodies[i].Gm = G * masses[i];
     }

\end{verbatim}

Precomputing $Gm$ yielded a 3\%ish performance improvement.

\medskip
 
\bibliographystyle{ieeetr}
\bibliography{bib}

\end{document}
